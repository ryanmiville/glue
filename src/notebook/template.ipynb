{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe77138",
   "metadata": {},
   "outputs": [],
   "source": [
    "%stop_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f056916",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c14331",
   "metadata": {},
   "outputs": [],
   "source": [
    "%iam_role IAM_ROLE_ARN\n",
    "%region us-east-1\n",
    "%glue_version 4.0\n",
    "%idle_timeout 120\n",
    "%number_of_workers 2\n",
    "%extra_jars \"s3://crawler-public/json/serde/json-serde.jar\"\n",
    "%spark_conf spark.sql.catalog.catalog.warehouse=s3://<your-warehouse-dir> --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.driver.maxResultSize=2g --conf spark.sql.catalog.catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog --conf spark.delta.logStore.class=org.apache.spark.sql.delta.storage.S3SingleDriverLogStore --conf spark.sql.shuffle.partitions=100\n",
    "%%configure\n",
    "{\n",
    "    \"datalake-formats\": \"iceberg,delta\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import com.amazonaws.services.glue.GlueContext\n",
    "import com.amazonaws.services.glue.util.JsonOptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.hadoop.fs._\n",
    "import java.net._\n",
    "\n",
    "def listPaths(path: String): List[String] = {\n",
    "\t\tval conf = spark.sparkContext.hadoopConfiguration\n",
    "\t\t\n",
    "\t\tFileSystem\n",
    "\t\t\t.get(URI.create(path), conf)\n",
    "\t\t\t.listStatus(new Path(path + \"/\"))\n",
    "\t\t\t.map(_.getPath.toString)\n",
    "\t\t\t.toList\n",
    "\t}\n",
    "\n",
    "def mostRecentPath(path: String): String = {\n",
    "    val conf = spark.sparkContext.hadoopConfiguration\n",
    "    \n",
    "    FileSystem\n",
    "      .get(URI.create(path), conf)\n",
    "      .listStatus(new Path(path + \"/\"))\n",
    "      .last\n",
    "      .getPath\n",
    "      .toString\n",
    "  }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue Spark",
   "language": "scala",
   "name": "glue_spark"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
